<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Yuxing Wang</title>
    <link>https://Yuxing-Wang-THU.github.io/project/</link>
      <atom:link href="https://Yuxing-Wang-THU.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 27 Sep 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Yuxing-Wang-THU.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://Yuxing-Wang-THU.github.io/project/</link>
    </image>
    
    <item>
      <title>ModularEvoGym</title>
      <link>https://Yuxing-Wang-THU.github.io/project/modularevogym/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/project/modularevogym/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./robot.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt; ModularEvoGym [1] is based on Evolution Gym [2], a large-scale benchmark for co-optimizing the design and control of Voxel-based Soft Robots (VSRs). We modified the original state representation to formulate a new modular observation space. The input state of the robot at time step $t$ is represented as $s_{t}^{c}=\lbrace s_{t}^{v},s_{t}^{g}\rbrace$, where $s_{t}^{v}=\lbrace s_{t}^{v_{1}}, s_{t}^{v_{2}},...,s_{t}^{v_N}\rbrace$, $s_{t}^{v_i}$ is composed of each voxel&#39;s local information which contains the relative position of its four corners with respect to the center of mass of the robot and its material information (e.g., &lt;b&gt;&lt;font color=Gray&gt;soft voxel&lt;/font&gt;&lt;/b&gt;, &lt;b&gt;rigid voxel&lt;/b&gt;, &lt;b&gt;&lt;font color=Darkorange&gt;horizontal actuator&lt;/font&gt;&lt;/b&gt; and &lt;b&gt;&lt;font color=DeepSkyBlue&gt;vertical actuator&lt;/font&gt;&lt;/b&gt;). $s_{t}^{g}$ is the task-related observation such as terrain information of the environment and goal-relevant information. During the simulation, voxels (except empty voxels) only sense locally, and based on the input sensory information, a controller outputs control signals to vary the volume of actuator voxels. The morphology of the robot is unchangeable during the interaction with the environment. &lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./robot2.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt; With the support of ModularEvoGym, we can do many interesting things. We modeled the local observations of all voxels as a sequence and adopted the self-attention mechanism [3] to develop a more efficient controller (shown below) that handles incompatible state-action spaces. This controller can be trained by popular Reinforcement Learning algorithms (e.g., PPO [4]) to simultaneously control a variety of robot morphologies.&lt;/p&gt; 
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./controller.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt; For encoding a VSR&#39;s morphology, apart from using methods such as direct encoding and Compositional Pattern Producing Network (CPPN) [5], which rely on having access to the whole design space, we provided another choice, Neural Cellular Automata (NCA) [6], which takes multiple actions to grow a robot from an initial seed (morphology), as shown below. NCA encodes complex patterns in a neural network and generates different developmental outcomes while using a smaller set of trainable parameters.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./design.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Built upon the aforementioned successes, we also presented an efficient Curriculum-based Co-design (CuCo) method for learning to design and control VSRs through an easy-to-difficult process [7]. The following pictures show a developmental process of a walker agent. For more details, please refer to &lt;a href=&#34;https://yuxing-wang-thu.github.io/publication/cuco/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CuCo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;$3 \times 3$ design space, $9$ voxels.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./1.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

$5 \times 5$ design space, $25$ voxels.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./2.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

$7 \times 7$ design space, $49$ voxels.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./3.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

$9 \times 9$ design space, $81$ voxels.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./4.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

$11 \times 11$ design space, $121$ voxels.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./5.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/Yuxing-Wang-THU/ModularEvoGym&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ModularEvoGym&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://evolutiongym.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evolution Gym: A Large-Scale Benchmark for Evolving Soft Robots&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Attention Is All You Need&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href=&#34;https://arxiv.org/abs/1707.06347&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proximal Policy Optimization Algorithms&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5] &lt;a href=&#34;https://link.springer.com/article/10.1007/s10710-007-9028-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Compositional Pattern Producing Network&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[6] &lt;a href=&#34;https://distill.pub/2020/growing-ca/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Neural Cellular Automata&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[7] &lt;a href=&#34;https://yuxing-wang-thu.github.io/publication/cuco/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Evolutionary Arts</title>
      <link>https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/</guid>
      <description>&lt;p style=&#34;text-align:justify&#34;;&gt;Using Compositional Pattern-Producing Network(CPPN) to generate pictures, very funny.&lt;/p&gt;
&lt;p&gt;Here is the &lt;a href=&#34;https://github.com/Yuxing-Wang-THU/Evolutionary-Arts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/a_hu10332d6ec3a754b8b8cfac83b926b1f2_26704_a55a3e289d74dd219c0bc5193d382472.jpg 400w,
               /project/evolutionary_arts/a_hu10332d6ec3a754b8b8cfac83b926b1f2_26704_d5a85f11e81fa636fb05230119bea761.jpg 760w,
               /project/evolutionary_arts/a_hu10332d6ec3a754b8b8cfac83b926b1f2_26704_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/a_hu10332d6ec3a754b8b8cfac83b926b1f2_26704_a55a3e289d74dd219c0bc5193d382472.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/b_hu39c428bcc29877a80a46cb34eac21bae_38293_4cb07847623e14b6652dbdd41f8828b5.jpg 400w,
               /project/evolutionary_arts/b_hu39c428bcc29877a80a46cb34eac21bae_38293_0308405e7647a05f38a4f4d765e48546.jpg 760w,
               /project/evolutionary_arts/b_hu39c428bcc29877a80a46cb34eac21bae_38293_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/b_hu39c428bcc29877a80a46cb34eac21bae_38293_4cb07847623e14b6652dbdd41f8828b5.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/c_hu28bee01178a13f6a332b6bab82fe4320_40159_ab2ad65a0b999e2b975c3e20f7eab211.jpg 400w,
               /project/evolutionary_arts/c_hu28bee01178a13f6a332b6bab82fe4320_40159_b97c77ac052d61906e3c1e404a039f2d.jpg 760w,
               /project/evolutionary_arts/c_hu28bee01178a13f6a332b6bab82fe4320_40159_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/c_hu28bee01178a13f6a332b6bab82fe4320_40159_ab2ad65a0b999e2b975c3e20f7eab211.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/d_hu656cc3699bc6a25c8e0dea527ac50132_106737_28dd5536ec9e84337563c8970bd68b3e.jpg 400w,
               /project/evolutionary_arts/d_hu656cc3699bc6a25c8e0dea527ac50132_106737_79923bd42492c8736b615cbdd6e95cd6.jpg 760w,
               /project/evolutionary_arts/d_hu656cc3699bc6a25c8e0dea527ac50132_106737_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/d_hu656cc3699bc6a25c8e0dea527ac50132_106737_28dd5536ec9e84337563c8970bd68b3e.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/e_hu2568418f64e513215520ef1ac53d0693_113338_5092de113907a9f459db65e337f383b0.jpg 400w,
               /project/evolutionary_arts/e_hu2568418f64e513215520ef1ac53d0693_113338_30581c73e35ad90414354ed434c68124.jpg 760w,
               /project/evolutionary_arts/e_hu2568418f64e513215520ef1ac53d0693_113338_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/e_hu2568418f64e513215520ef1ac53d0693_113338_5092de113907a9f459db65e337f383b0.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/f_hufd03d26cfd97fa27e8837c25d1fbbb5e_148623_8f446c048d8088a0e67466a53613d08f.jpg 400w,
               /project/evolutionary_arts/f_hufd03d26cfd97fa27e8837c25d1fbbb5e_148623_09d1257d318c2445f6e991a58ad01b4a.jpg 760w,
               /project/evolutionary_arts/f_hufd03d26cfd97fa27e8837c25d1fbbb5e_148623_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/f_hufd03d26cfd97fa27e8837c25d1fbbb5e_148623_8f446c048d8088a0e67466a53613d08f.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/evolutionary_arts/g_hue4f9ebd7b3f226ba07b620bdec68bafc_182563_d5222d556a59a30f912c52dcd9ba8adc.jpg 400w,
               /project/evolutionary_arts/g_hue4f9ebd7b3f226ba07b620bdec68bafc_182563_be476563b1e4ab398389aeadf12aa948.jpg 760w,
               /project/evolutionary_arts/g_hue4f9ebd7b3f226ba07b620bdec68bafc_182563_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;https://Yuxing-Wang-THU.github.io/project/evolutionary_arts/g_hue4f9ebd7b3f226ba07b620bdec68bafc_182563_d5222d556a59a30f912c52dcd9ba8adc.jpg&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>International Underwater Robot Competition</title>
      <link>https://Yuxing-Wang-THU.github.io/project/fish/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/project/fish/</guid>
      <description>&lt;p style=&#34;text-align:justify&#34;;&gt;The International Underwater Robot Competition is an international contest sponsored by the International League of Underwater Robots (ILUR) supported by both the UNESCO Industry-University Cooperative Education &amp; the Ministry of Educationâ€™s Innovative Education Method Steering Committee.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./ff.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;In the 2D Simulation League, teams of autonomous software programs play in a two-dimensional virtual playground represented by a central server, called URWPGSim2DServer. This server knows everything about the game, i.e. the current position of all fishes and the physics. The game further relies on communication between the server and each agent. Each fish receives relative and noisy input from its virtual sensors and performs some basic commands to influence its environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Survival Challenge&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;In this contest, we first control the light blue simulated fish to attack the yellow simulated fishes controlled by the defender (the other team), while the defender can also use a dark blue simulated fish to block the attacker&#39;s attack. The game changes the side after 5 minutes. We won the first prize in IURC 2017 and IURC 2018.&lt;/p&gt;
&lt;p&gt;A short video&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/catcher.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p&gt;&lt;strong&gt;Artistic Swimming&lt;/strong&gt;&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;In this contest, ten red simulated fishes are controlled by each team to perform artistic swimming and one yellow simulated fish is controlled by the server to disrupt other fishes.&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/swimmer.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
</description>
    </item>
    
    <item>
      <title>A wearable hand rehabilitation robot</title>
      <link>https://Yuxing-Wang-THU.github.io/project/hand/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/project/hand/</guid>
      <description>&lt;p style=&#34;text-align:justify&#34;;&gt; In this project, we design a wearable hand rehabilitation robot, which consists of a data glove, a manipulator and an APP. This system allows the patient to use a healthy hand to operate the rehabilitation glove, thus controlling the robot to drive the disabled hand to reproduce its movements. At the same time, combined with the rehabilitation program customized by professional physicians integrated into the APP, the system can provide corresponding rehabilitation training for different degrees of disability.&lt;/p&gt;
&lt;p&gt;A short vedio&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/my_video.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
</description>
    </item>
    
  </channel>
</rss>
